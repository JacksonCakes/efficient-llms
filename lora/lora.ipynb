{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchinfo\n",
    "import torch.nn as nn\n",
    "from layers import CifarLoRAModel\n",
    "import torchvision.transforms as transforms\n",
    "from layers import CifarModel\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Allow training and testing with GPU if exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize model,loss, optimizer and tensorboard writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "model = CifarModel(hidden_dim=128,num_classes=len(classes)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define test function to evaluate test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(inputs)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "    return 100 * correct // total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train it for 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,epochs):\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 500 == 499:  # print every 500 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 500:.3f}')\n",
    "                writer.add_scalar('Loss/train',running_loss / 500,i+1)\n",
    "                running_loss = 0.0\n",
    "        test_acc = test(model)\n",
    "        \n",
    "        writer.add_scalar('Accuracy/test',test_acc,epoch)\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 2.137\n",
      "[1,  1000] loss: 1.880\n",
      "[1,  1500] loss: 1.759\n",
      "Accuracy of the network on the 10000 test images: 39 %\n",
      "[2,   500] loss: 1.689\n",
      "[2,  1000] loss: 1.625\n",
      "[2,  1500] loss: 1.597\n",
      "Accuracy of the network on the 10000 test images: 45 %\n",
      "[3,   500] loss: 1.548\n",
      "[3,  1000] loss: 1.523\n",
      "[3,  1500] loss: 1.517\n",
      "Accuracy of the network on the 10000 test images: 47 %\n",
      "[4,   500] loss: 1.464\n",
      "[4,  1000] loss: 1.450\n",
      "[4,  1500] loss: 1.451\n",
      "Accuracy of the network on the 10000 test images: 48 %\n",
      "[5,   500] loss: 1.403\n",
      "[5,  1000] loss: 1.396\n",
      "[5,  1500] loss: 1.387\n",
      "Accuracy of the network on the 10000 test images: 49 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "train(model=model,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_model.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_model.pth'\n",
    "lora_model = CifarLoRAModel(hidden_dim=128,num_classes=len(classes),rank=32,alpha=1).to(device)\n",
    "lora_model.load_state_dict(torch.load(PATH),strict=False)\n",
    "optimizer = optim.SGD(lora_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(model,input_size=(batch_size,32*32*3), col_names = (\"input_size\", \"output_size\", \"num_params\"), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "CifarLoRAModel                           [32, 3072]                [32, 10]                  --\n",
       "├─Linear: 1-1                            [32, 3072]                [32, 128]                 (393,344)\n",
       "├─LoRALinear: 1-2                        [32, 3072]                [32, 128]                 102,400\n",
       "├─Linear: 1-3                            [32, 128]                 [32, 128]                 (16,512)\n",
       "├─LoRALinear: 1-4                        [32, 128]                 [32, 128]                 8,192\n",
       "├─Linear: 1-5                            [32, 128]                 [32, 10]                  (1,290)\n",
       "├─LoRALinear: 1-6                        [32, 128]                 [32, 10]                  4,416\n",
       "===================================================================================================================\n",
       "Total params: 526,154\n",
       "Trainable params: 115,008\n",
       "Non-trainable params: 411,146\n",
       "Total mult-adds (Units.MEGABYTES): 13.16\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.39\n",
       "Forward/backward pass size (MB): 0.14\n",
       "Params size (MB): 2.10\n",
       "Estimated Total Size (MB): 2.63\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(lora_model,input_size=(batch_size,32*32*3), col_names = (\"input_size\", \"output_size\", \"num_params\"), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 1.333\n",
      "[1,  1000] loss: 1.316\n",
      "[1,  1500] loss: 1.320\n",
      "Accuracy of the network on the 10000 test images: 50 %\n",
      "[2,   500] loss: 1.309\n",
      "[2,  1000] loss: 1.306\n",
      "[2,  1500] loss: 1.308\n",
      "Accuracy of the network on the 10000 test images: 50 %\n",
      "[3,   500] loss: 1.293\n",
      "[3,  1000] loss: 1.301\n",
      "[3,  1500] loss: 1.303\n",
      "Accuracy of the network on the 10000 test images: 50 %\n",
      "[4,   500] loss: 1.288\n",
      "[4,  1000] loss: 1.292\n",
      "[4,  1500] loss: 1.288\n",
      "Accuracy of the network on the 10000 test images: 51 %\n",
      "[5,   500] loss: 1.272\n",
      "[5,  1000] loss: 1.286\n",
      "[5,  1500] loss: 1.278\n",
      "Accuracy of the network on the 10000 test images: 51 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "train(lora_model,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
